{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T16:11:46.663650600Z",
     "start_time": "2024-11-15T16:11:43.286817900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                  *  F:\\Program_Files\\Anaconda\n",
      "py3.6.3                  F:\\Program_Files\\Anaconda\\envs\\py3.6.3\n",
      "vlfm                     F:\\Program_Files\\Anaconda\\envs\\vlfm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e35e728-ad6c-405f-877e-45e8938c5d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "import dgl\n",
    "from models.GCN import GCN\n",
    "import xgboost as xgb\n",
    "from models.RNN import RNN\n",
    "from models.SVM import SVM\n",
    "from models.SVM import SVM_impl\n",
    "from models.DecisionTree import DecisionTreeID3, DecisionTreeCART\n",
    "from models.LogisticRegression import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f30baef2b8b30d41",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.661646600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 使用KNN图构建\n",
    "def create_graph_from_data(features, n_neighbors=15):  # 增加邻居数\n",
    "    knn_graph = kneighbors_graph(features, n_neighbors=n_neighbors, mode='connectivity', include_self=False)\n",
    "    knn_graph = knn_graph.astype(np.float32).todense()\n",
    "\n",
    "    # 转换为DGL图\n",
    "    src, dst = np.where(knn_graph > 0)  # 获取非零元素的索引\n",
    "    src = torch.tensor(src, dtype=torch.int64)\n",
    "    dst = torch.tensor(dst, dtype=torch.int64)\n",
    "\n",
    "    # 创建DGL图\n",
    "    g = dgl.graph((src, dst))\n",
    "    g.ndata['feat'] = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "    # 计算节点度数并进行归一化\n",
    "    in_degrees = g.in_degrees().float()\n",
    "    norm = 1.0 / in_degrees\n",
    "    g.ndata['norm'] = norm\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9ec92a9d0e1dfaa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.663650600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "mushroom_data = pd.read_csv('data/mushrooms.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "254ed0a60a4c7647",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T16:11:46.665648800Z",
     "start_time": "2024-11-15T16:11:46.665648800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 分离目标和特征\n",
    "target = mushroom_data['class']\n",
    "inputs = mushroom_data.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37245583b08951e6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.666648100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, target, test_size=0.2, random_state=24, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45ad3fe82b7ca465",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.669649600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 编码\n",
    "enc_i = OrdinalEncoder()\n",
    "enc_t = LabelEncoder()\n",
    "\n",
    "x_train_transf = enc_i.fit_transform(X_train)\n",
    "x_test_transf = enc_i.transform(X_test)\n",
    "\n",
    "y_train_transf = enc_t.fit_transform(y_train)\n",
    "y_test_transf = enc_t.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b6f9d1-65d4-45e2-8dd1-4564fd3c90d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定分类任务的类别数\n",
    "num_classes = len(np.unique(y_train_transf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae4dc605ed96d96d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.671648200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 构建训练图\n",
    "X_train_tensor = torch.tensor(x_train_transf, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_transf, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(x_test_transf, dtype=torch.float32)\n",
    "\n",
    "# 数据标准化\n",
    "X_train_tensor = F.normalize(X_train_tensor, p=2, dim=1)\n",
    "X_test_tensor = F.normalize(X_test_tensor, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "650b2f0b-80a5-48da-970f-a6fe3d0b3288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化数据\n",
    "scaler = StandardScaler()\n",
    "x_train_transf_scaler = scaler.fit_transform(x_train_transf)\n",
    "x_test_transf_scaler = scaler.transform(x_test_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5d7927bdab729f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T16:11:46.760339600Z",
     "start_time": "2024-11-15T16:11:46.674647500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 0.6931\n",
      "Iteration 100: Loss = 0.4415\n",
      "Iteration 200: Loss = 0.3561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 300: Loss = 0.3149\n",
      "Iteration 400: Loss = 0.2906\n",
      "Iteration 500: Loss = 0.2745\n",
      "Early stopping at iteration 597, Loss = 0.2633\n",
      "Training Accuracy (Logistic Regression): 90.71%\n",
      "Test Accuracy (Logistic Regression): 89.78%\n"
     ]
    }
   ],
   "source": [
    "# 初始化并训练Logistic Regression模型\n",
    "log_reg_model = LogisticRegression(learning_rate=0.01, n_iter=1000, verbose=True, early_stopping=True)\n",
    "log_reg_model.fit(x_train_transf_scaler, y_train_transf)\n",
    "\n",
    "# 预测与评估\n",
    "log_reg_predictions = log_reg_model.predict(x_test_transf_scaler)\n",
    "accuracy_log_reg = accuracy_score(y_test_transf, log_reg_predictions)\n",
    "\n",
    "# 计算训练集准确率\n",
    "train_predictions = log_reg_model.predict(x_train_transf_scaler)\n",
    "train_accuracy = accuracy_score(y_train_transf, train_predictions)\n",
    "print(f'Training Accuracy (Logistic Regression): {train_accuracy * 100:.2f}%')\n",
    "\n",
    "# 输出测试准确率\n",
    "print(f'Test Accuracy (Logistic Regression): {accuracy_log_reg * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d578b91c4f058a29",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.675650600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 初始化并训练SVM模型\n",
    "svm_model = SVM(C=1.0, kernel='linear', max_iter=1000)\n",
    "svm_model.fit(x_train_transf_scaler, y_train_transf)\n",
    "\n",
    "# 预测与评估\n",
    "svm_predictions = svm_model.predict(x_test_transf_scaler)\n",
    "accuracy_svm = accuracy_score(y_test_transf, svm_predictions)\n",
    "\n",
    "# 输出测试准确率\n",
    "print(f'Test Accuracy (SVM): {accuracy_svm * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7557c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.5170\n",
      "Epoch [20/100], Loss: 0.3298\n",
      "Epoch [30/100], Loss: 0.2514\n",
      "Epoch [40/100], Loss: 0.2223\n",
      "Epoch [50/100], Loss: 0.2029\n",
      "Epoch [60/100], Loss: 0.1871\n",
      "Epoch [70/100], Loss: 0.2490\n",
      "Epoch [80/100], Loss: 0.1728\n",
      "Epoch [90/100], Loss: 0.1689\n",
      "Epoch [100/100], Loss: 0.1615\n",
      "Test Accuracy: 94.65%\n"
     ]
    }
   ],
   "source": [
    "# 定义超参数\n",
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_size = 256\n",
    "output_size = num_classes\n",
    "num_layers = 2\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "# 初始化RNN模型\n",
    "rnn_model = RNN(input_size, hidden_size, output_size, num_layers)\n",
    "rnn_model = rnn_model.to(X_train_tensor.device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 训练RNN模型\n",
    "for epoch in range(num_epochs):\n",
    "    rnn_model.train()\n",
    "    outputs = rnn_model(X_train_tensor.unsqueeze(1))  # 增加维度以匹配RNN输入\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 测试RNN模型\n",
    "rnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = rnn_model(X_test_tensor.unsqueeze(1))  # 增加维度以匹配RNN输入\n",
    "    _, predicted = torch.max(test_outputs.data, 1)\n",
    "    accuracy = accuracy_score(y_test_transf, predicted.cpu().numpy())\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e836e3246c1bb00e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.677647Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (ID3): 97.66%\n"
     ]
    }
   ],
   "source": [
    "# 使用ID3算法训练决策树\n",
    "id3_model = DecisionTreeID3(max_depth=5)  # 可以根据需要调整最大深度\n",
    "id3_model.fit(x_train_transf, y_train_transf)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "id3_predictions = id3_model.predict(x_test_transf)\n",
    "\n",
    "# 计算准确率\n",
    "id3_accuracy = accuracy_score(y_test_transf, id3_predictions)\n",
    "print(f'Test Accuracy (ID3): {id3_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ac228-92c9-4792-b0c7-bdec93b005d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (CART): 97.54%\n"
     ]
    }
   ],
   "source": [
    "# 使用CART算法训练决策树\n",
    "cart_model = DecisionTreeCART(max_depth=5)  # 可以根据需要调整最大深度\n",
    "cart_model.fit(x_train_transf, y_train_transf)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "cart_predictions = cart_model.predict(x_test_transf)\n",
    "\n",
    "# 计算准确率\n",
    "cart_accuracy = accuracy_score(y_test_transf, cart_predictions)\n",
    "print(f'Test Accuracy (CART): {cart_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53aa5d49f3c395b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.678647Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# XGBoost训练\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(x_train_transf, label\u001b[38;5;241m=\u001b[39my_train_transf)\n\u001b[0;32m      3\u001b[0m dtest \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(x_test_transf, label\u001b[38;5;241m=\u001b[39my_test_transf)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# XGBoost超参数设置\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "# XGBoost训练\n",
    "dtrain = xgb.DMatrix(x_train_transf, label=y_train_transf)\n",
    "dtest = xgb.DMatrix(x_test_transf, label=y_test_transf)\n",
    "\n",
    "# XGBoost超参数设置\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # 二分类\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 6,  # 树的最大深度\n",
    "    'eta': 0.1,  # 学习率\n",
    "    'subsample': 0.8,  # 子样本比例\n",
    "    'colsample_bytree': 0.8,  # 树的列采样\n",
    "    'n_jobs': 4\n",
    "}\n",
    "\n",
    "# 训练\n",
    "num_round = 1000\n",
    "bst = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# 预测\n",
    "y_pred_xgb = bst.predict(dtest)\n",
    "y_pred_xgb = (y_pred_xgb > 0.5).astype(int)  # 二分类，阈值设置为0.5\n",
    "\n",
    "# 计算准确率\n",
    "accuracy_xgb = accuracy_score(y_test_transf, y_pred_xgb)\n",
    "print(f'Test Accuracy (XGBoost): {accuracy_xgb * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c648b8e2bedbc2d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.679646600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/GNNsIMPL/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7000444531440735, Train Accuracy: 0.5379\n",
      "Epoch 10, Loss: 0.640451967716217, Train Accuracy: 0.6206\n",
      "Epoch 20, Loss: 0.4707907736301422, Train Accuracy: 0.8170\n",
      "Epoch 30, Loss: 0.3156937062740326, Train Accuracy: 0.8891\n",
      "Epoch 40, Loss: 0.22044765949249268, Train Accuracy: 0.9109\n",
      "Epoch 50, Loss: 0.1253221482038498, Train Accuracy: 0.9546\n",
      "Epoch 60, Loss: 0.0984925702214241, Train Accuracy: 0.9595\n",
      "Epoch 70, Loss: 0.06610783189535141, Train Accuracy: 0.9828\n",
      "Epoch 80, Loss: 0.0564689114689827, Train Accuracy: 0.9812\n",
      "Epoch 90, Loss: 0.03838644176721573, Train Accuracy: 0.9868\n",
      "Epoch 100, Loss: 0.03533089533448219, Train Accuracy: 0.9854\n",
      "Epoch 110, Loss: 0.02958783507347107, Train Accuracy: 0.9925\n",
      "Epoch 120, Loss: 0.024208160117268562, Train Accuracy: 0.9946\n",
      "Epoch 130, Loss: 0.025786491110920906, Train Accuracy: 0.9928\n",
      "Epoch 140, Loss: 0.02466065250337124, Train Accuracy: 0.9922\n",
      "Epoch 150, Loss: 0.01867557503283024, Train Accuracy: 0.9952\n",
      "Epoch 160, Loss: 0.018140053376555443, Train Accuracy: 0.9934\n",
      "Epoch 170, Loss: 0.019678547978401184, Train Accuracy: 0.9949\n",
      "Epoch 180, Loss: 0.023419130593538284, Train Accuracy: 0.9925\n",
      "Epoch 190, Loss: 0.017350174486637115, Train Accuracy: 0.9943\n",
      "Epoch 200, Loss: 0.021184654906392097, Train Accuracy: 0.9925\n",
      "Epoch 210, Loss: 0.023234689608216286, Train Accuracy: 0.9909\n",
      "Epoch 220, Loss: 0.019754910841584206, Train Accuracy: 0.9940\n",
      "Epoch 230, Loss: 0.018946899101138115, Train Accuracy: 0.9935\n",
      "Epoch 240, Loss: 0.019056417047977448, Train Accuracy: 0.9951\n",
      "Epoch 250, Loss: 0.014420120045542717, Train Accuracy: 0.9963\n",
      "Epoch 260, Loss: 0.018710747361183167, Train Accuracy: 0.9958\n",
      "Epoch 270, Loss: 0.01735820807516575, Train Accuracy: 0.9948\n",
      "Epoch 280, Loss: 0.01853383705019951, Train Accuracy: 0.9946\n",
      "Epoch 290, Loss: 0.015970388427376747, Train Accuracy: 0.9952\n",
      "Epoch 300, Loss: 0.01689203456044197, Train Accuracy: 0.9942\n",
      "Epoch 310, Loss: 0.017248354852199554, Train Accuracy: 0.9946\n",
      "Epoch 320, Loss: 0.021827131509780884, Train Accuracy: 0.9937\n",
      "Epoch 330, Loss: 0.014202841557562351, Train Accuracy: 0.9960\n",
      "Epoch 340, Loss: 0.014336928725242615, Train Accuracy: 0.9971\n",
      "Epoch 350, Loss: 0.01532286312431097, Train Accuracy: 0.9960\n",
      "Epoch 360, Loss: 0.013959119096398354, Train Accuracy: 0.9960\n",
      "Epoch 370, Loss: 0.01748766005039215, Train Accuracy: 0.9955\n",
      "Epoch 380, Loss: 0.015303295105695724, Train Accuracy: 0.9952\n",
      "Epoch 390, Loss: 0.016111385077238083, Train Accuracy: 0.9946\n",
      "Epoch 400, Loss: 0.02142316848039627, Train Accuracy: 0.9931\n",
      "Epoch 410, Loss: 0.018146023154258728, Train Accuracy: 0.9955\n",
      "Epoch 420, Loss: 0.01489506009966135, Train Accuracy: 0.9965\n",
      "Epoch 430, Loss: 0.014426695182919502, Train Accuracy: 0.9962\n",
      "Epoch 440, Loss: 0.0202163178473711, Train Accuracy: 0.9934\n",
      "Epoch 450, Loss: 0.015889950096607208, Train Accuracy: 0.9954\n",
      "Epoch 460, Loss: 0.01889619417488575, Train Accuracy: 0.9934\n",
      "Epoch 470, Loss: 0.013139218091964722, Train Accuracy: 0.9958\n",
      "Epoch 480, Loss: 0.012105513364076614, Train Accuracy: 0.9977\n",
      "Epoch 490, Loss: 0.01461575273424387, Train Accuracy: 0.9962\n",
      "Epoch 500, Loss: 0.017304452136158943, Train Accuracy: 0.9955\n",
      "Epoch 510, Loss: 0.017405586317181587, Train Accuracy: 0.9937\n",
      "Epoch 520, Loss: 0.01300332136452198, Train Accuracy: 0.9960\n",
      "Epoch 530, Loss: 0.016334377229213715, Train Accuracy: 0.9955\n",
      "Epoch 540, Loss: 0.01088524330407381, Train Accuracy: 0.9974\n",
      "Epoch 550, Loss: 0.01571197435259819, Train Accuracy: 0.9948\n",
      "Epoch 560, Loss: 0.013763157650828362, Train Accuracy: 0.9963\n",
      "Epoch 570, Loss: 0.013658333569765091, Train Accuracy: 0.9963\n",
      "Epoch 580, Loss: 0.014489457942545414, Train Accuracy: 0.9962\n",
      "Epoch 590, Loss: 0.01542728953063488, Train Accuracy: 0.9957\n",
      "Epoch 600, Loss: 0.013204683549702168, Train Accuracy: 0.9977\n",
      "Epoch 610, Loss: 0.01348367240279913, Train Accuracy: 0.9971\n",
      "Epoch 620, Loss: 0.016354264691472054, Train Accuracy: 0.9965\n",
      "Epoch 630, Loss: 0.021044394001364708, Train Accuracy: 0.9914\n",
      "Epoch 640, Loss: 0.015259532257914543, Train Accuracy: 0.9960\n",
      "Epoch 650, Loss: 0.013241437263786793, Train Accuracy: 0.9971\n",
      "Epoch 660, Loss: 0.016220146790146828, Train Accuracy: 0.9954\n",
      "Epoch 670, Loss: 0.02009466104209423, Train Accuracy: 0.9935\n",
      "Epoch 680, Loss: 0.01965901628136635, Train Accuracy: 0.9942\n",
      "Epoch 690, Loss: 0.021181894466280937, Train Accuracy: 0.9935\n",
      "Epoch 700, Loss: 0.014700219966471195, Train Accuracy: 0.9962\n",
      "Epoch 710, Loss: 0.012803178280591965, Train Accuracy: 0.9963\n",
      "Epoch 720, Loss: 0.01645476743578911, Train Accuracy: 0.9946\n",
      "Epoch 730, Loss: 0.01673685759305954, Train Accuracy: 0.9942\n",
      "Epoch 740, Loss: 0.014120819978415966, Train Accuracy: 0.9963\n",
      "Epoch 750, Loss: 0.012949002906680107, Train Accuracy: 0.9963\n",
      "Epoch 760, Loss: 0.013954256661236286, Train Accuracy: 0.9966\n",
      "Epoch 770, Loss: 0.015544695779681206, Train Accuracy: 0.9958\n",
      "Epoch 780, Loss: 0.013194984756410122, Train Accuracy: 0.9963\n",
      "Epoch 790, Loss: 0.013634725473821163, Train Accuracy: 0.9966\n",
      "Epoch 800, Loss: 0.01478511281311512, Train Accuracy: 0.9957\n",
      "Epoch 810, Loss: 0.014390494674444199, Train Accuracy: 0.9955\n",
      "Epoch 820, Loss: 0.01574067771434784, Train Accuracy: 0.9958\n",
      "Epoch 830, Loss: 0.0164432842284441, Train Accuracy: 0.9951\n",
      "Epoch 840, Loss: 0.01154094934463501, Train Accuracy: 0.9978\n",
      "Epoch 850, Loss: 0.017020929604768753, Train Accuracy: 0.9951\n",
      "Epoch 860, Loss: 0.016993805766105652, Train Accuracy: 0.9942\n",
      "Epoch 870, Loss: 0.019946644082665443, Train Accuracy: 0.9934\n",
      "Epoch 880, Loss: 0.01292450912296772, Train Accuracy: 0.9963\n",
      "Epoch 890, Loss: 0.014027521945536137, Train Accuracy: 0.9962\n",
      "Epoch 900, Loss: 0.014916285872459412, Train Accuracy: 0.9957\n",
      "Epoch 910, Loss: 0.013034751638770103, Train Accuracy: 0.9966\n",
      "Epoch 920, Loss: 0.014909990131855011, Train Accuracy: 0.9962\n",
      "Epoch 930, Loss: 0.01689726673066616, Train Accuracy: 0.9954\n",
      "Epoch 940, Loss: 0.013358981348574162, Train Accuracy: 0.9971\n",
      "Epoch 950, Loss: 0.01429043710231781, Train Accuracy: 0.9951\n",
      "Epoch 960, Loss: 0.01870504766702652, Train Accuracy: 0.9955\n",
      "Epoch 970, Loss: 0.0190731193870306, Train Accuracy: 0.9940\n",
      "Epoch 980, Loss: 0.01500587910413742, Train Accuracy: 0.9948\n",
      "Epoch 990, Loss: 0.013996724970638752, Train Accuracy: 0.9963\n",
      "Test Accuracy: 95.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/GNNsIMPL/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "G_train = create_graph_from_data(X_train_tensor, n_neighbors=15)  # 增加邻居数\n",
    "\n",
    "# 定义超参数\n",
    "in_feats = X_train_tensor.shape[1]\n",
    "h_feats = 256  # 增大隐藏层维度\n",
    "num_classes = len(np.unique(y_train_transf))\n",
    "dropout = 0.5\n",
    "\n",
    "# 创建GCN模型\n",
    "model = GCN(in_feats=in_feats, hidden_feats=h_feats, out_feats=num_classes, dropout_rate=dropout)\n",
    "\n",
    "# 优化器与学习率调度器\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.005, weight_decay=1e-5)  # 使用AdamW\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练过程\n",
    "num_epochs = 100  # 增加训练轮数\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    # 前向传播\n",
    "    logits = model(G_train, G_train.ndata['feat'])\n",
    "\n",
    "    # 计算损失\n",
    "    loss = loss_fn(logits, y_train_tensor)\n",
    "\n",
    "    # 反向传播和优化\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 更新学习率\n",
    "    scheduler.step()\n",
    "\n",
    "    # 记录训练损失\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    # 计算训练精度\n",
    "    _, train_preds = torch.max(logits, dim=1)\n",
    "    train_accuracy = accuracy_score(y_train_tensor.cpu(), train_preds.cpu())\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # 每10轮打印一次损失和训练精度\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}, Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "# 测试过程\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    G_test = create_graph_from_data(X_test_tensor, n_neighbors=15)\n",
    "    logits_test = model(G_test, G_test.ndata['feat'])\n",
    "    predictions = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "    # 计算测试准确率\n",
    "    accuracy = accuracy_score(y_test_transf, predictions.numpy())\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
