{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T16:11:46.663650600Z",
     "start_time": "2024-11-15T16:11:43.286817900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     D:\\Anaconda3\n",
      "AntiFraud                D:\\Anaconda3\\envs\\AntiFraud\n",
      "AntiFraud2            *  D:\\Anaconda3\\envs\\AntiFraud2\n",
      "Basket                   D:\\Anaconda3\\envs\\Basket\n",
      "JadeWeb                  D:\\Anaconda3\\envs\\JadeWeb\n",
      "ML                       D:\\Anaconda3\\envs\\ML\n",
      "streamlit3               D:\\Anaconda3\\envs\\streamlit3\n",
      "AntiFraud2               d:\\Anaconda3\\envs\\AntiFraud2\n",
      "ML                       d:\\Anaconda3\\envs\\ML\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e35e728-ad6c-405f-877e-45e8938c5d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\AntiFraud2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "import dgl\n",
    "from models.GCN import GCN\n",
    "# import xgboost as xgb\n",
    "from models.RNN import RNN\n",
    "from models.SVM import SVM\n",
    "from models.DecisionTree import DecisionTreeID3, DecisionTreeCART\n",
    "from models.LogisticRegression import LogisticRegression\n",
    "from models.RandomForest import train_random_forest\n",
    "from models.CNN import SimpleCNN\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30baef2b8b30d41",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.661646600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 使用KNN图构建\n",
    "def create_graph_from_data(features, n_neighbors=15):  # 增加邻居数\n",
    "    knn_graph = kneighbors_graph(features, n_neighbors=n_neighbors, mode='connectivity', include_self=False)\n",
    "    knn_graph = knn_graph.astype(np.float32).todense()\n",
    "\n",
    "    # 转换为DGL图\n",
    "    src, dst = np.where(knn_graph > 0)  # 获取非零元素的索引\n",
    "    src = torch.tensor(src, dtype=torch.int64)\n",
    "    dst = torch.tensor(dst, dtype=torch.int64)\n",
    "\n",
    "    # 创建DGL图\n",
    "    g = dgl.graph((src, dst))\n",
    "    g.ndata['feat'] = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "    # 计算节点度数并进行归一化\n",
    "    in_degrees = g.in_degrees().float()\n",
    "    norm = 1.0 / in_degrees\n",
    "    g.ndata['norm'] = norm\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ec92a9d0e1dfaa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.663650600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "mushroom_data = pd.read_csv('data/mushrooms.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254ed0a60a4c7647",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T16:11:46.665648800Z",
     "start_time": "2024-11-15T16:11:46.665648800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 分离目标和特征\n",
    "target = mushroom_data['class']\n",
    "inputs = mushroom_data.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37245583b08951e6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.666648100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, target, test_size=0.2, random_state=24, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45ad3fe82b7ca465",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.669649600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 编码\n",
    "enc_i = OrdinalEncoder()\n",
    "enc_t = LabelEncoder()\n",
    "\n",
    "x_train_transf = enc_i.fit_transform(X_train)\n",
    "x_test_transf = enc_i.transform(X_test)\n",
    "\n",
    "y_train_transf = enc_t.fit_transform(y_train)\n",
    "y_test_transf = enc_t.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36b6f9d1-65d4-45e2-8dd1-4564fd3c90d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定分类任务的类别数\n",
    "num_classes = len(np.unique(y_train_transf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae4dc605ed96d96d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.671648200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 构建训练图\n",
    "X_train_tensor = torch.tensor(x_train_transf, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_transf, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(x_test_transf, dtype=torch.float32)\n",
    "\n",
    "# 数据标准化\n",
    "X_train_tensor = F.normalize(X_train_tensor, p=2, dim=1)\n",
    "X_test_tensor = F.normalize(X_test_tensor, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "650b2f0b-80a5-48da-970f-a6fe3d0b3288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化数据\n",
    "scaler = StandardScaler()\n",
    "x_train_transf_scaler = scaler.fit_transform(x_train_transf)\n",
    "x_test_transf_scaler = scaler.transform(x_test_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5d7927bdab729f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T16:11:46.760339600Z",
     "start_time": "2024-11-15T16:11:46.674647500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 0.6931\n",
      "Iteration 100: Loss = 0.4415\n",
      "Iteration 200: Loss = 0.3561\n",
      "Iteration 300: Loss = 0.3149\n",
      "Iteration 400: Loss = 0.2906\n",
      "Iteration 500: Loss = 0.2745\n",
      "Early stopping at iteration 597, Loss = 0.2633\n",
      "Training Accuracy (Logistic Regression): 90.71%\n",
      "Test Accuracy (Logistic Regression): 89.78%\n"
     ]
    }
   ],
   "source": [
    "# 初始化并训练Logistic Regression模型\n",
    "log_reg_model = LogisticRegression(learning_rate=0.01, n_iter=1000, verbose=True, early_stopping=True)\n",
    "log_reg_model.fit(x_train_transf_scaler, y_train_transf)\n",
    "\n",
    "# 预测与评估\n",
    "log_reg_predictions = log_reg_model.predict(x_test_transf_scaler)\n",
    "accuracy_log_reg = accuracy_score(y_test_transf, log_reg_predictions)\n",
    "\n",
    "# 计算训练集准确率\n",
    "train_predictions = log_reg_model.predict(x_train_transf_scaler)\n",
    "train_accuracy = accuracy_score(y_train_transf, train_predictions)\n",
    "print(f'Training Accuracy (Logistic Regression): {train_accuracy * 100:.2f}%')\n",
    "\n",
    "# 输出测试准确率\n",
    "print(f'Test Accuracy (Logistic Regression): {accuracy_log_reg * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d578b91c4f058a29",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.675650600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# SVM训练：使用自定义的SVM实现\\nsvm_model = SVM(kernel='rbf', learning_rate=0.001, n_iters=10, C=1.0)\\nsvm_model.train(x_train_transf_scaler, y_train_transf)\\n\\n# 预测\\nsvm_predictions = svm_model.predict(x_test_transf_scaler)\\n\\n# 计算测试准确率\\naccuracy_svm = accuracy_score(y_test_transf, svm_predictions)\\nprint(f'Test Accuracy (SVM): {accuracy_svm * 100:.2f}%')\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# SVM训练：使用自定义的SVM实现\n",
    "svm_model = SVM(kernel='rbf', learning_rate=0.001, n_iters=10, C=1.0)\n",
    "svm_model.train(x_train_transf_scaler, y_train_transf)\n",
    "\n",
    "# 预测\n",
    "svm_predictions = svm_model.predict(x_test_transf_scaler)\n",
    "\n",
    "# 计算测试准确率\n",
    "accuracy_svm = accuracy_score(y_test_transf, svm_predictions)\n",
    "print(f'Test Accuracy (SVM): {accuracy_svm * 100:.2f}%')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e836e3246c1bb00e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.677647Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (ID3): 97.66%\n"
     ]
    }
   ],
   "source": [
    "# 使用ID3算法训练决策树\n",
    "id3_model = DecisionTreeID3(max_depth=5)  # 可以根据需要调整最大深度\n",
    "id3_model.fit(x_train_transf, y_train_transf)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "id3_predictions = id3_model.predict(x_test_transf)\n",
    "\n",
    "# 计算准确率\n",
    "id3_accuracy = accuracy_score(y_test_transf, id3_predictions)\n",
    "print(f'Test Accuracy (ID3): {id3_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf7ac228-92c9-4792-b0c7-bdec93b005d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (CART): 97.54%\n"
     ]
    }
   ],
   "source": [
    "# 使用CART算法训练决策树\n",
    "cart_model = DecisionTreeCART(max_depth=5)  # 可以根据需要调整最大深度\n",
    "cart_model.fit(x_train_transf, y_train_transf)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "cart_predictions = cart_model.predict(x_test_transf)\n",
    "\n",
    "# 计算准确率\n",
    "cart_accuracy = accuracy_score(y_test_transf, cart_predictions)\n",
    "print(f'Test Accuracy (CART): {cart_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c648b8e2bedbc2d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T16:11:46.679646600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\AntiFraud2\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7545259594917297, Train Accuracy: 0.4411\n",
      "Epoch 10, Loss: 0.47636887431144714, Train Accuracy: 0.7964\n",
      "Epoch 20, Loss: 0.3649664521217346, Train Accuracy: 0.8561\n",
      "Epoch 30, Loss: 0.2502155601978302, Train Accuracy: 0.8855\n",
      "Epoch 40, Loss: 0.22881688177585602, Train Accuracy: 0.9084\n",
      "Epoch 50, Loss: 0.18591415882110596, Train Accuracy: 0.9280\n",
      "Epoch 60, Loss: 0.176894873380661, Train Accuracy: 0.9352\n",
      "Epoch 70, Loss: 0.14234943687915802, Train Accuracy: 0.9425\n",
      "Epoch 80, Loss: 0.11782790720462799, Train Accuracy: 0.9638\n",
      "Epoch 90, Loss: 0.09628640115261078, Train Accuracy: 0.9706\n",
      "Test Accuracy: 96.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\AntiFraud2\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "G_train = create_graph_from_data(X_train_tensor, n_neighbors=15)  # 增加邻居数\n",
    "\n",
    "# 定义超参数\n",
    "in_feats = X_train_tensor.shape[1]\n",
    "h_feats = 256  # 增大隐藏层维度\n",
    "num_classes = len(np.unique(y_train_transf))\n",
    "dropout = 0.5\n",
    "\n",
    "# 创建GCN模型\n",
    "model = GCN(in_feats=in_feats, hidden_feats=h_feats, out_feats=num_classes, dropout_rate=dropout)\n",
    "\n",
    "# 优化器与学习率调度器\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.005, weight_decay=1e-5)  # 使用AdamW\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练过程\n",
    "num_epochs = 100  # 增加训练轮数\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    # 前向传播\n",
    "    logits = model(G_train, G_train.ndata['feat'])\n",
    "\n",
    "    # 计算损失\n",
    "    loss = loss_fn(logits, y_train_tensor)\n",
    "\n",
    "    # 反向传播和优化\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 更新学习率\n",
    "    scheduler.step()\n",
    "\n",
    "    # 记录训练损失\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    # 计算训练精度\n",
    "    _, train_preds = torch.max(logits, dim=1)\n",
    "    train_accuracy = accuracy_score(y_train_tensor.cpu(), train_preds.cpu())\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # 每10轮打印一次损失和训练精度\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}, Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "# 测试过程\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    G_test = create_graph_from_data(X_test_tensor, n_neighbors=15)\n",
    "    logits_test = model(G_test, G_test.ndata['feat'])\n",
    "    predictions = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "    # 计算测试准确率\n",
    "    accuracy = accuracy_score(y_test_transf, predictions.numpy())\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dac23fe-93c1-4baa-9c42-8bca73140865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       842\n",
      "           1       0.93      0.97      0.95       783\n",
      "\n",
      "    accuracy                           0.95      1625\n",
      "   macro avg       0.95      0.95      0.95      1625\n",
      "weighted avg       0.95      0.95      0.95      1625\n",
      "\n",
      "Confusion Matrix:\n",
      " [[787  55]\n",
      " [ 24 759]]\n",
      "AUC Score: 0.952013996960348\n",
      "AP Score: 0.9186213587592897\n"
     ]
    }
   ],
   "source": [
    "# 随机森林\n",
    "rf_model = train_random_forest(x_train_transf_scaler, y_train_transf, x_test_transf_scaler, y_test_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "183852ec-7e09-418f-9d12-d11b899ee12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "163/163 [==============================] - 2s 5ms/step - loss: 0.5042 - accuracy: 0.8186 - val_loss: 0.3267 - val_accuracy: 0.9031\n",
      "Epoch 2/20\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.2592 - accuracy: 0.9100 - val_loss: 0.1890 - val_accuracy: 0.9231\n",
      "Epoch 3/20\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1666 - accuracy: 0.9404 - val_loss: 0.1363 - val_accuracy: 0.9508\n",
      "Epoch 4/20\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1258 - accuracy: 0.9496 - val_loss: 0.0968 - val_accuracy: 0.9615\n",
      "Epoch 5/20\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1026 - accuracy: 0.9590 - val_loss: 0.0936 - val_accuracy: 0.9600\n",
      "Epoch 6/20\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0829 - accuracy: 0.9677 - val_loss: 0.0677 - val_accuracy: 0.9777\n",
      "Epoch 7/20\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0721 - accuracy: 0.9750 - val_loss: 0.0755 - val_accuracy: 0.9646\n",
      "Epoch 8/20\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0591 - accuracy: 0.9786 - val_loss: 0.0532 - val_accuracy: 0.9838\n",
      "Epoch 9/20\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0486 - accuracy: 0.9838 - val_loss: 0.0521 - val_accuracy: 0.9831\n",
      "Epoch 10/20\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0415 - accuracy: 0.9863 - val_loss: 0.0341 - val_accuracy: 0.9900\n",
      "Epoch 11/20\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0368 - accuracy: 0.9871 - val_loss: 0.0286 - val_accuracy: 0.9938\n",
      "Epoch 12/20\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 0.0285 - val_accuracy: 0.9938\n",
      "Epoch 13/20\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0272 - accuracy: 0.9917 - val_loss: 0.0221 - val_accuracy: 0.9923\n",
      "Epoch 14/20\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.0173 - val_accuracy: 0.9954\n",
      "Epoch 15/20\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0203 - accuracy: 0.9948 - val_loss: 0.0170 - val_accuracy: 0.9969\n",
      "Epoch 16/20\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9963 - val_loss: 0.0190 - val_accuracy: 0.9931\n",
      "Epoch 17/20\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.0208 - val_accuracy: 0.9962\n",
      "Epoch 18/20\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.0108 - val_accuracy: 0.9985\n",
      "Epoch 19/20\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 0.0121 - val_accuracy: 0.9977\n",
      "Epoch 20/20\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0123 - accuracy: 0.9975 - val_loss: 0.0113 - val_accuracy: 0.9969\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       842\n",
      "           1       1.00      1.00      1.00       783\n",
      "\n",
      "    accuracy                           1.00      1625\n",
      "   macro avg       1.00      1.00      1.00      1625\n",
      "weighted avg       1.00      1.00      1.00      1625\n",
      "\n",
      "AUC: 1.0000\n",
      "Average Precision (AP): 1.0000\n"
     ]
    }
   ],
   "source": [
    "# CNN \n",
    "# 初始化和训练 CNN 模型\n",
    "input_shape = (x_train_transf_scaler.shape[1], 1)\n",
    "cnn_model = SimpleCNN(input_shape=input_shape)\n",
    "# 训练 CNN 模型\n",
    "cnn_model.train(x_train_transf_scaler, y_train_transf, epochs=20, batch_size=32, validation_split=0.2) \n",
    "# 评估 CNN 模型\n",
    "cnn_model.evaluate(x_test_transf_scaler, y_test_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa0fcf6-84f8-46b3-b1c6-a4b5e0470af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost训练\n",
    "dtrain = xgb.DMatrix(x_train_transf, label=y_train_transf)\n",
    "dtest = xgb.DMatrix(x_test_transf, label=y_test_transf)\n",
    "\n",
    "# XGBoost超参数设置\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # 二分类\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 6,  # 树的最大深度\n",
    "    'eta': 0.1,  # 学习率\n",
    "    'subsample': 0.8,  # 子样本比例\n",
    "    'colsample_bytree': 0.8,  # 树的列采样\n",
    "    'n_jobs': 4\n",
    "}\n",
    "\n",
    "# 训练\n",
    "num_round = 1000\n",
    "bst = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# 预测\n",
    "y_pred_xgb = bst.predict(dtest)\n",
    "y_pred_xgb = (y_pred_xgb > 0.5).astype(int)  # 二分类，阈值设置为0.5\n",
    "\n",
    "# 计算准确率\n",
    "accuracy_xgb = accuracy_score(y_test_transf, y_pred_xgb)\n",
    "print(f'Test Accuracy (XGBoost): {accuracy_xgb * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb183e64-873c-40bc-8d92-37703cf2caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN训练\n",
    "rnn_model = RNN(input_size=x_train_transf_scaler.shape[1], hidden_size=256, output_size=num_classes)\n",
    "rnn_model.train(x_train_transf_scaler.tolist(), y_train_transf.tolist(), epochs=100, learning_rate=1e-3)\n",
    "\n",
    "# 预测\n",
    "rnn_predictions = rnn_model.predict(x_test_transf_scaler.tolist())\n",
    "\n",
    "# 计算测试准确率\n",
    "accuracy_rnn = accuracy_score(y_test_transf, rnn_predictions)\n",
    "print(f'Test Accuracy (RNN): {accuracy_rnn * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e80e96a-fa4b-4c22-b1ea-f94ce6c84ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AntiFraud2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
