# 对比学习聚类
    对比学习是通过比较正负样本对来进行学习的，对于一般的对比学习方法，正样本往往是从样本自身得到的，比如对该样本做增强（augmentation），而负样本则是从batch中随机挑选的样本。然而这种构造方法可能会面临两个问题：
    * 为了加强模型的分辨能力，我们往往需要在一个batch中加入足够多的负样本，许多实验也表明大的batch size可以提高模型性能。然而由于一般的对比学习方法需要对batch中的样本进行两两比较，计算复杂度为 $O(n^2)$，这就导致batch size会受到显存大小的约束，给对比学习的应用带来了障碍。
    * 随机挑选负样本的方式可能会将一些实际上很相似的样本作为负样本（例如若锚定样本是一只狗的图片，而随机挑出来的负样本恰好也是一只狗的图片，那么即使两个样本实际上很相似，模型也会将其作为负样本），这样可能会影响模型的性能。
    聚类对比学习就是想要解决上述的问题，顾名思义，该方法不直接做两两样本的对比，而是先对样本进行聚类，然后在类之间进行对比学习，由于样本的“类别”是通过无监督的聚类方法得到的，因此整个学习过程中并不需要样本标签，仍然还是在做自监督学习。通过聚类后再对比的操作，我们就可以大大减小对比的数量，降低计算复杂度，而且同一类下的不同样本也互为正样本，不会将相似的样本当做负样本。
